
# üöÄ WeWeb : Le Commencement d'une Aventure Num√©rique

![alt text](image.png)

| **Aspect** | **D√©tail** |
|---|---|
| **Date de cr√©ation** | 2024 |
| **Fondateurs** | Alice Dupont et Ben Lemaire |
| **Activit√© principale** | Conception et r√©alisation de sites web √©l√©gants et performants pour PME locales |

## I. L'Id√©e Fondatrice

Tout commence dans un petit garage transform√© en bureau, o√π **Alice** (designer web talentueuse) et **Ben** (d√©veloppeur passionn√©) d√©cident de s'associer. 

**Constat** : Beaucoup de PME ont des sites dat√©s, lents et mal optimis√©s.

**Objectif WeWeb** : Proposer des solutions num√©riques sur mesure ax√©es sur :
- ‚ö° **Vitesse de chargement**
- üéØ **Exp√©rience utilisateur (UX)**

## II. L'Infrastructure Initiale : Le "Starter Pack" du LAN

### üîå 1. Connectivit√© et C≈ìur du R√©seau

| √âquipement | R√¥le |
|---|---|
| **Routeur Wi-Fi** | Passerelle Internet & Distributeur DHCP |
| **Switch 8 Ports** | C√¢blage Ethernet pour connexion stable |








### üíº 2. Postes de Travail et Ressources

- **2 PC Windows** : Alice (Design) & Ben (D√©veloppement)
- **Imprimante R√©seau** : Partage des contrats et maquettes
- **Serveur NAS** : Centralisation des fichiers clients, projets, sauvegarde

## III. Le D√©fi pour les TD

WeWeb fait face √† ses premi√®res limites :
- ‚ö†Ô∏è Performance web insuffisante
- üì¶ Besoin d'une solution **CDN (Content Delivery Network)**

**Votre mission** : Accompagner WeWeb dans sa croissance en analysant et √©voluant son infrastructure.

---

# üõ†Ô∏è Cahier de Travaux Dirig√©s - Infrastructure & R√©seau WeWeb

Ce cahier couvre l'**√©volution de l'infrastructure WeWeb** √† travers des ateliers pratiques.

---

## üíª Atelier 1 : Mod√©lisation du R√©seau Local (LAN) & Fondamentaux OSI

**Objectif** : Visualiser l'architecture de base et r√©viser les couches OSI.

### 1.1 Repr√©sentation Physique

**T√¢che** : Dessiner ou mod√©liser le r√©seau initial avec **Cisco Packet Tracer**.

![Diagramme r√©seau petit bureau : 2 PC, serveur, imprimante ‚Üí switch ‚Üí routeur Wi-Fi]

**Composants** : 2 PC, NAS, imprimante, switch, routeur Wi-Fi

**Livrable** : Sch√©ma montrant connexions filaires vs. Wi-Fi


## Diagramme

```mermaid
graph TB
    Internet[Internet]
    Router[Routeur Wi-Fi]
    Switch[Switch 8 Ports]
    PC1[PC Windows - Alice]
    PC2[PC Windows - Ben]
    NAS[Serveur NAS]
    Printer[Imprimante R√©seau]
    
    Internet -->|Ethernet| Router
    Router -->|Ethernet| Switch
    Router -->|Wi-Fi| PC1
    Router -->|Wi-Fi| PC2
    Switch -->|Ethernet| PC1
    Switch -->|Ethernet| PC2
    Switch -->|Ethernet| NAS
    Switch -->|Ethernet| Printer
```

### 1.2 Identification des R√¥les

| Question | R√©ponse |
|---|---|
| **Passerelle** ? | |
| **Point de concentration filaire** ? | |
| **R√¥le du NAS** ? | |


J'ai d√©j√† fourni la r√©ponse au format Markdown dans ma premi√®re r√©ponse, ainsi que dans ma deuxi√®me r√©ponse.

Voici la version compl√®te en **Markdown** (format tableau) :

| Question | R√©ponse |
|---|---|
| **Passerelle** ? | Une **passerelle** (ou **gateway**) est un n≈ìud de r√©seau qui sert de point d'arr√™t pour les donn√©es avant de passer d'un r√©seau √† un autre, agissant comme un **traducteur** pour communiquer entre des r√©seaux utilisant des protocoles diff√©rents. |
| **Point de concentration filaire** ? | Le **point de concentration filaire** est un √©quipement r√©seau (g√©n√©ralement un **Switch** ou, anciennement, un Hub) utilis√© pour **interconnecter physiquement** et g√©rer la circulation des donn√©es entre plusieurs dispositifs au sein d'un m√™me r√©seau local (LAN). |
| **R√¥le du NAS** ? | Le **NAS** (**Network-Attached Storage**) est un serveur de stockage d√©di√© connect√© au r√©seau dont le r√¥le principal est de fournir un espace **centralis√© et partag√©** pour le stockage, la sauvegarde et l'acc√®s aux fichiers pour tous les utilisateurs du r√©seau. |




**Livrable** : Tableau synth√©tique des r√¥les et protocoles (DHCP, NAT)

### 1.3 Exercice : Devinez la Couche OSI üßê

Associez chaque description au **num√©ro de couche OSI** (1-7) :

| Description | Couche |
|:---|:---:|
| Transmission brute des bits (c√¢bles, ondes radio) | |
| Acc√®s au support (MAC) - Exemple : Ethernet | |
| Adressage logique (IP) et routage | |
| Communication bout √† bout (TCP/UDP) | |
| Gestion des sessions | |
| Traduction, chiffrement, compression | |
| Services applicatifs - Exemple : HTTP, DNS | |

---

## üì± Atelier 2 : R√©seau PAM et Int√©gration WSL

**Objectif** : Ma√Ætriser le **PAM (Point d'Acc√®s Mobile)** et la mise en r√©seau **WSL**.

### üìå Qu'est-ce qu'un PAM ?

**PAM = Hotspot mobile** transformant votre smartphone en routeur Wi-Fi (NAT/DHCP) utilisant la 4G/5G.

### 2.1 Mise en Place du PAM

‚úÖ Activer le **Point d'Acc√®s Mobile** sur votre smartphone  
‚úÖ Connecter votre **PC Windows** en Wi-Fi

### 2.2 Analyse du R√©seau H√¥te

**Commandes** :
```bash
ipconfig          # Identifier IP PC et passerelle
ping [smartphone] # Tester la connectivit√©
```

**Livrable** : Adresses IP + r√©sultat `ping`

Je cr√©√© un page web minimale avec node comme

app.js + index.html

Mon adresse :
172.25.159.246

Sur mon smartphone :
172.25.159.246:3000



### 2.3 Int√©gration WSL 2

## V√©rifier configuration Windows

![alt text](image-1.png)

**Commandes WSL** :
```bash
ip a              # Trouver l'IP du WSL
ping [PC_IP]      # Ping vers Windows
ping [Passerelle] # Ping vers smartphone
```

![alt text](image-2.png)

```bash
ping 172.25.159.246 
```
![alt text](image-3.png)

**Tests de connectivit√© √† valider** :
1. ‚úì PC Windows ‚Üí WSL
2. ‚úì WSL ‚Üí PC Windows
3. ‚úì WSL ‚Üí Passerelle PAM

**Livrable** : IP du WSL + r√©sultats des 3 tests


## Configurer ngnix pour les ressources cdn

![alt text](image-6.png)
---

## üåê Atelier 3 : CDN Statique Local

**Objectif** : D√©ployer un **CDN local** pour am√©liorer la performance des ressources statiques.

## Exemple sur Smartphone

![alt text](image-4.png)

### 3.1 Conception et S√©curit√© du CDN

**T√¢che** : Dessiner l'architecture CDN (serveur source ‚Üí caches ‚Üí utilisateurs)
```mermaid
flowchart LR
  Win[Machine Windows
Nodejs
Site Web]
  WSL[WSL
Nginx - CDN]
  Phone[Smartphone
Partage reseau]
  BrowserPC[Navigateur Windows]
  BrowserPhone[Navigateur Smartphone]

  Phone -->|partage reseau| Win

  BrowserPC -->|requete HTTP| Win
  BrowserPhone -->|requete HTTP| Win

  Win -->|demande ressources statiques| WSL
  WSL -->|sert CDN| Win

  Win -->|reponse Web| BrowserPC
  Win -->|reponse Web| BrowserPhone

```


# Mettre en place un syst√®me de cache dans Ngnix

#### Configuration Nginx pour Cache CDN

**√âtape 1** : Modifier la configuration Nginx
```bash
sudo nano /etc/nginx/sites-available/default
```

**√âtape 2** : Ajouter les directives de cache
```nginx
# Configuration du cache
proxy_cache_path /var/cache/nginx levels=1:2 keys_zone=cdn_cache:10m max_size=1g inactive=60m;

server {
    listen 80;
    server_name _;
    
    # Servir les fichiers statiques avec cache
    location ~* \.(css|js|jpg|png|gif|ico|svg|woff|woff2)$ {
        root /var/www/cdn;
        expires 30d;  # Cache navigateur
        add_header Cache-Control "public, immutable";
    }
    
    # Proxy avec cache serveur
    location /api/ {
        proxy_pass http://127.0.0.1:3000;
        proxy_cache cdn_cache;
        proxy_cache_valid 200 10m;
        proxy_cache_use_stale error timeout updating http_500 http_502 http_503 http_504;
        add_header X-Cache-Status $upstream_cache_status;
    }
}
```

**√âtape 3** : Tester et valider
```bash
sudo nginx -t
sudo systemctl restart nginx
curl -I http://[IP_WSL]/style.css  # V√©rifier headers Cache-Control
```

**V√©rifier le cache** :
```bash
ls -la /var/cache/nginx/  # Fichiers en cache
```




#### ‚ùì Question 1 : DMZ
Faut-il placer les serveurs CDN (contenu public) en **DMZ** ?  

**Oui, les serveurs CDN doivent √™tre plac√©s en DMZ.**

**Justification :**
- Les serveurs CDN servent du contenu **public** accessible depuis Internet
- La DMZ isole ces serveurs du r√©seau interne (LAN) pour limiter les risques de s√©curit√©
- En cas de compromission d'un serveur CDN, l'attaquant ne peut pas acc√©der directement aux donn√©es sensibles du r√©seau interne
- Les pare-feu contr√¥lent les flux : Internet ‚Üî DMZ (autoris√©) et DMZ ‚Üî R√©seau interne (restreint)


#### ‚ùì Question 2 : Op√©rations Infrastructure
Citer et d√©crire **3 op√©rations essentielles** pour g√©rer le CDN :
- (ex: mise en cache, purge, journalisation)


**Livrable** : Sch√©ma + analyses DMZ & op√©rations

### 3.2 Impl√©mentation avec WSL et PAM

**√âtape 1** : Installer un serveur web dans WSL
```bash
# Ubuntu/Debian
sudo apt update && sudo apt install nginx
sudo systemctl start nginx
```
### Test de la page par d√©faut ngnix

![alt text](image-5.png)


**√âtape 2** : Cr√©er contenu statique
```bash
mkdir -p /var/www/cdn
echo "/* CSS */" > /var/www/cdn/style.css
echo "// JS" > /var/www/cdn/script.js
```

**√âtape 3** : Tester depuis le smartphone
```
http://[IP_WSL]/style.css
http://[IP_WSL]/script.js
```

**Livrable** : Commandes + Preuve d'acc√®s r√©ussi

C'est une excellente clarification \! Le choix de l'outil de test est crucial. **Cypress** et **Selenium** sont les deux g√©ants dans le domaine de l'automatisation des tests **End-to-End (E2E)**.

Pour la nature de cet atelier (v√©rification rapide du front-end et de l'int√©gration CDN), nous allons choisir **Cypress** pour sa simplicit√© d'installation et sa rapidit√© d'ex√©cution, tout en notant que **Selenium** est l'outil de pr√©dilection pour les tests multi-navigateurs plus complexes.

Voici la mise √† jour de l'**Atelier 4** int√©grant cette sp√©cification.

-----

## ‚öôÔ∏è Atelier 4 : Tests Automatis√©s et Environnement Isol√© (VM)

**Objectif** : D√©ployer un environnement de test isol√© (VM) capable d'ex√©cuter des tests de performance et de fonctionnalit√© sur le site web servi par le CDN local (WSL/Nginx).

-----

### 4.1. Justification de la Machine Virtuelle (VM)

L'utilisation d'une **Machine Virtuelle (VM)** est une pratique standard en d√©veloppement et en assurance qualit√© pour plusieurs raisons fondamentales :

1.  **Isolation** : La VM cr√©e un environnement de test **s√©par√©** et **isol√©** du syst√®me d'exploitation h√¥te.
2.  **Reproductibilit√©** : Elle permet de figer un √©tat pr√©cis du syst√®me via un **snapshot**, garantissant des conditions de test identiques √† chaque ex√©cution.
3.  **Simulation** : Elle simule facilement des environnements clients ou serveurs sp√©cifiques.
4.  **S√©curit√©** : Tester du code ou des configurations r√©seau risqu√©es se fait sans danger pour le r√©seau interne.

-----

### 4.2. Choix Technologiques pour la VM

| Cat√©gorie | Technologie sugg√©r√©e | R√¥le & Justification |
| :--- | :--- | :--- |
| **Hyperviseur** | **VirtualBox** (Gratuit) ou **Hyper-V** | Cr√©e et g√®re la VM sur le PC h√¥te. |
| **OS Invit√©** | **Ubuntu Desktop** (pour l'affichage graphique de Cypress) | Syst√®me sur lequel les outils seront install√©s. La version **Desktop** est requise pour pouvoir lancer l'interface graphique de Cypress. |
| **Outil de Test E2E** | **Cypress** | Pour l'atelier : **Cypress** est plus simple et rapide √† installer (Node.js) et offre une excellente exp√©rience pour les tests modernes du site web. *Alternative :* **Selenium** est √† pr√©f√©rer si l'objectif est de tester une compatibilit√© stricte sur tous les navigateurs (Chrome, Firefox, Edge, etc.). |
| **Outil de Test de Performance** | **Apache JMeter** | Simule des charges lourdes pour mesurer la vitesse de chargement et l'efficacit√© du cache CDN. |

-----

### 4.3. Impl√©mentation Pratique : Configuration Cypress

**T√¢che** : Pr√©parer la VM pour ex√©cuter un test **Cypress** qui v√©rifie l'accessibilit√© du site web via le CDN local.

1.  **Installation de l'Hyperviseur et de l'OS** : Installer **VirtualBox** et cr√©er une VM avec **Ubuntu Desktop**.
2.  **Configuration R√©seau** : S'assurer que la VM est configur√©e en mode **NAT** ou **Bridge** pour acc√©der √† l'IP du WSL/Nginx (votre CDN local).
3.  **Installation des Pr√©requis** (dans la VM Ubuntu) : Installer **Node.js** et **npm** (n√©cessaires pour Cypress).
    ```bash
    sudo apt update
    sudo apt install nodejs npm
    ```
4.  **Installation de Cypress** : Cr√©er un r√©pertoire de projet et installer Cypress localement.
    ```bash
    mkdir weweb-e2e-tests
    cd weweb-e2e-tests
    npm init -y
    npm install cypress --save-dev
    ```
5.  **Cr√©ation du Test** : Ouvrir Cypress, cr√©er un fichier de test (`cdn_access.cy.js`) et y √©crire un test simple.

#### Exemple de Script Cypress

Ce script simule un utilisateur et v√©rifie que le site, et par extension ses ressources statiques (servies par le CDN), sont accessibles :

```javascript
// cdn_access.cy.js
describe('V√©rification de l\'accessibilit√© du site via CDN', () => {
  it('Doit charger la page principale et v√©rifier l\'acc√®s √† une ressource CDN', () => {
    // Remplacer [IP_WSL] par l'adresse IP de votre WSL/Nginx
    const wsl_ip = 'http://[IP_WSL]'; 
    
    // 1. Acc√©der au serveur CDN local
    cy.visit(wsl_ip); 
    
    // 2. V√©rifier que la page par d√©faut Nginx s'affiche (Titre)
    cy.title().should('include', 'Welcome to nginx!');
    
    // 3. V√©rifier que la ressource statique (CSS) est accessible (simul√© par un cy.request)
    // Cela confirme que la route et le cache Nginx fonctionnent pour les fichiers statiques.
    cy.request({
      url: `${wsl_ip}/style.css`,
      failOnStatusCode: true, // Doit retourner 200
    }).its('headers')
      .its('content-type')
      .should('include', 'text/css');
  });
});
```

**Livrable** :

1.  La justification (en 3 points maximum) du choix de **Cypress** sur **Selenium** pour cet atelier.
2.  Le r√©sultat du test Cypress (succ√®s/√©chec) dans l'interface graphique de la VM apr√®s ex√©cution du script ci-dessus.
   

## Installation node sur Centos
iutiliser loadkeys fr sur centos pour clavier en fran√ßais

curl -sL https://rpm.nodesource.com/setup_20.x | sudo bash -

sudo yum install nodejs

# Alice et Ben se mettent au Container

Ils installent docker desktop et v√©rifie l'installation:

docker --version
docker info

Ils testent l'image officielle

docker run hello-world

il v√©rie la cr√©ation d'une image avec 

docker ps -a

Ils affichent les images

docker images


-----


# üö¢ Atelier 5 : Cr√©ation d'une API M√©t√©o Marine en Microservice (Conteneuris√©)

**Objectif :** Concevoir, mod√©liser et impl√©menter une API de m√©t√©o marine sous forme de microservice, en utilisant **PHP** et **MySQL**, et en conteneurisant l'ensemble avec **Docker**. Ce service fournira des bulletins exploitables pour les applications de WeWeb.

### 5.1 Conception de l'Architecture Microservice (Conteneuris√©e)

* **Contexte :** Le d√©ploiement de l'API s'effectuera via Docker et Docker Compose, garantissant l'isolation des d√©pendances (PHP, MySQL).
* **T√¢che :** Dessiner l'architecture de ce microservice, en incluant :
    * Le client (application web/mobile de WeWeb)
    * L'API Gateway (point d'entr√©e unique)
    * Le Microservice "M√©t√©o Marine" (Conteneur PHP/Nginx)
    * La base de donn√©es MySQL (Conteneur d√©di√©)
    * Une source de donn√©es externe (ex: API de m√©t√©o marine publique simul√©e)

```mermaid
graph TD
    Client[Application Client WeWeb] --> ApiGw[API Gateway]
    
    subgraph Environnement de Production Docker
        ApiGw --> Proxy[Reverse Proxy / Load Balancer]
        Proxy --> Microservice[Microservice M√©t√©o Marine Conteneur PHP/Nginx]
        Microservice --> DB[Base de Donn√©es MySQL Conteneur]
        Microservice --> ExternalAPI[Source de Donn√©es M√©t√©o Externe Simul√©e]
    end
    
    style Microservice fill:#f9f,stroke:#333,stroke-width:2px
    style DB fill:#ccf,stroke:#333,stroke-width:2px
````

### 5.2 Mod√©lisation de la Base de Donn√©es (MySQL)

  * **T√¢che :** Concevoir le sch√©ma de la base de donn√©es MySQL pour stocker les bulletins m√©t√©o marins.
  * **Tables Minimales :**
      * `ports` : Stocke les emplacements maritimes.
      * `bulletins_meteo` : Stocke les pr√©visions (li√©es √† un port).
  * **Champs Sugger√©s :**

| Table | Champs | Type / Contrainte | R√¥le |
| :--- | :--- | :--- | :--- |
| **`ports`** | `id` | INT (PK, AI) | Identifiant unique |
| | `nom_port` | VARCHAR(255) | Nom du port |
| | `latitude`, `longitude` | DECIMAL(10, 6) | Position GPS |
| **`bulletins_meteo`** | `id` | INT (PK, AI) | Identifiant unique |
| | `port_id` | INT (FK vers `ports.id`) | Port concern√© par le bulletin |
| | `date_bulletin` | DATETIME | Date/Heure de la pr√©vision |
| | `force_vent` | INT | Force du vent (en Beaufort) |
| | `etat_mer` | VARCHAR(100) | Description (Ex: Belle, agit√©e) |

  * **Livrable :** Le sch√©ma de la base de donn√©es (le tableau ci-dessus).

### 5.3 D√©veloppement du Microservice (PHP)

  * **T√¢che :** D√©crire les principales √©tapes pour cr√©er la logique m√©tier en PHP.
  * **Endpoints D√©finis (API REST) :**

| M√©thode | Endpoint | Description |
| :---: | :--- | :--- |
| `GET` | `/api/meteo/ports` | Liste tous les ports disponibles. |
| `GET` | `/api/meteo/ports/{id_port}/bulletin` | Obtient le dernier bulletin pour un port sp√©cifique. |

  * **Logique M√©tier :** Le script PHP doit recevoir une requ√™te HTTP, interroger la base de donn√©es MySQL, et formater le r√©sultat en **JSON** avant de le renvoyer.
  * **Livrable :** Une description textuelle d√©taill√©e des √©tapes de d√©veloppement et des endpoints d√©finis.

### 5.4 D√©ploiement et Int√©gration (Docker)

  * **T√¢che :** Expliquer les composants n√©cessaires pour conteneuriser le service (Docker Compose).
  * **Composants Docker :**
    1.  **Service `app` :** Conteneur bas√© sur PHP-FPM, contenant le code de l'API.
    2.  **Service `web` :** Conteneur bas√© sur Nginx, servant de reverse proxy pour `app` et g√©rant les requ√™tes HTTP.
    3.  **Service `db` :** Conteneur bas√© sur MySQL, pour la persistance des donn√©es.
  * **T√¢che :** D√©crire comment le service `app` et le service `db` communiqueront (via le r√©seau interne Docker).
  * **Test d'Acc√®s :**
      * D√©marrer les services avec `docker compose up -d`.
      * Tester l'acc√®s √† l'API depuis le PC h√¥te ou le WSL en utilisant `curl` :
          * `curl http://localhost:[PORT_NGINX]/api/meteo/ports`
  * **Livrable :** L'explication des services Docker n√©cessaires et l'exemple de commande de test `curl`.

-----



## Pour d√©bugger :

### Pour tester la base :
Je teste la base de donn√©e
```bash
docker exec -it postgres_contact psql -U user -d contactsdb
```
Je tape la commande pour voir si une table existe
```
\dt
```

### Je lance le debug sur docker
Avec l'id ou le nom du container
```bash
docker logs f5fac1160aba 
```

![alt text](image-7.png)
La table n'existe pas. Je peux supprimer les volumes et en recr√©er.

```bash
docker-compose down -v

docker-compose up -d --build
```
## Quelques bonnes pratiques

* Utiliser les volumes pour persister les donn√©es au del√† du cycle de vie du conteneur.
* Utiliser les networks pour isoler les conteneurs.
* Utiliser les labels pour baliser les conteneurs.
* Utiliser les ports pour exposer les services aux r√©seaux.
* Utiliser les d√©pendances pour g√©rer les d√©pendances du conteneur.
* Utiliser les buildargs pour optimiser l'image du conteneur.
* Utiliser les environnements pour g√©rer les variables d'environnement.
* Utiliser les healthcheck pour v√©rifier l'√©tat du conteneur.

## üíª Atelier 6 : Infrastructure as Code
D'accord. Voici le texte des 20 exercices (TD) demand√©s, bas√©s sur les modules **builtin** simples et ciblant sp√©cifiquement `alpine1`, `alpine2`, ou les deux, incluant la v√©rification de la pr√©sence des paquets pour les installations/d√©sinstallations.

---

## üéØ 20 T√¢ches D√©taill√©es (TD) de Gestion Syst√®me

### Gestion de Fichiers et de R√©pertoires

1.  **Cr√©ation de R√©pertoire (alpine1) :** Cr√©er le r√©pertoire `/opt/config_backup` sur **`alpine1`** uniquement. Assurer qu'il appartient √† l'utilisateur `ops` et au groupe `ops`, avec des permissions `0750`.
2.  **Lien Symbolique (alpine2) :** Cr√©er un lien symbolique `/etc/motd_link` qui pointe vers `/etc/motd` sur **`alpine2`** uniquement.
3.  **Copie de Fichier (Tous) :** Copier un script local nomm√© `monitor.sh` (situ√© dans `files/`) vers `/usr/local/bin/monitor.sh` sur **tous les h√¥tes**, en s'assurant qu'il est ex√©cutable (`mode: '0755'`).
4.  **D√©ploiement de Template (alpine1) :** Utiliser un template Jinja2 (`templates/app.conf.j2`) pour g√©n√©rer le fichier de configuration `/etc/app/app.conf` sur **`alpine1`**, en injectant la variable `${{ app_version }}`.
5.  **Suppression de Fichier (alpine2) :** Supprimer un ancien fichier de journal `/var/log/app.old` si celui-ci existe sur **`alpine2`**.

---

### Gestion de Paquets et Services (Pr√©sence Assur√©e)

6.  **Installation de Paquet (alpine1) :** Assurer que le paquet `vim` est **pr√©sent** sur **`alpine1`** uniquement.
7.  **D√©sinstallation de Paquet (alpine2) :** Assurer que le paquet `telnet` est **absent** (d√©sinstall√©) sur **`alpine2`** uniquement.
8.  **Installation de Paquet (Tous) :** Assurer que le paquet `python3` est install√© avec la **derni√®re version** disponible sur **tous les h√¥tes**.
9.  **D√©marrage de Service (alpine1) :** D√©marrer le service `ssh` et s'assurer qu'il est **activ√©** au d√©marrage du syst√®me sur **`alpine1`**.
10. **Red√©marrage Conditionnel (alpine2) :** Red√©marrer le service `nginx` (en utilisant un **Handler**) sur **`alpine2`** uniquement si le fichier de configuration a √©t√© modifi√©.

---

### Gestion d'Utilisateurs et de Groupes

11. **Cr√©ation d'Utilisateur (alpine1) :** Cr√©er l'utilisateur `auditeur` avec un shell `/bin/false` sur **`alpine1`**.
12. **Gestion de Groupe (alpine2) :** Assurer que le groupe `admins_locaux` existe sur **`alpine2`**.
13. **Ajout √† un Groupe (alpine2) :** Ajouter l'utilisateur `deployer` au groupe secondaire `docker` sur **`alpine2`**.
14. **Cl√© SSH (Tous) :** S'assurer que la cl√© publique SSH stock√©e dans `files/sysadmin.pub` est ajout√©e au compte `root` sur **tous les h√¥tes**.

---

### Logique et Ex√©cution de Commandes

15. **Ex√©cution de Commande Simple (alpine1) :** Ex√©cuter la commande `uptime` et ignorer les erreurs potentielles sur **`alpine1`**.
16. **Enregistrement de Sortie (alpine2) :** Ex√©cuter la commande `df -h /` et **enregistrer** le r√©sultat dans une variable nomm√©e `espace_disque_alpine2` sur **`alpine2`**.
17. **Affichage de Variable (alpine2) :** Utiliser `ansible.builtin.debug` pour **afficher** le contenu de la variable `espace_disque_alpine2` enregistr√©e pr√©c√©demment, en ciblant **`alpine2`**.
18. **D√©finition de Fact Dynamique (Tous) :** Utiliser `ansible.builtin.set_fact` pour d√©finir une variable `distro` √©gale au nom de la distribution Linux (`ansible_distribution`) sur **tous les h√¥tes**.

---

### Manipulation de Fichiers (Lignes et Blocs)

19. **Ajout de Ligne (alpine1) :** S'assurer que la ligne `ClientAliveInterval 300` est pr√©sente dans le fichier de configuration SSH `/etc/ssh/sshd_config` sur **`alpine1`**.
20. **Gestion de Bloc (alpine2) :** Ajouter un **bloc** de configuration (`blockinfile`) √† la fin du fichier `/etc/hosts` sur **`alpine2`** pour y ins√©rer l'adresse IP de `alpine1`, entour√© de marqueurs.

## üì± Atelier 7 : D√©ploiement avec Ansible



-----

## üìù Travail Dirig√© : Environnement de Recette Minimaliste avec Docker et Ansible

### **Objectif G√©n√©ral**

Mettre en place un environnement de recette bas√© sur un conteneur Alpine en utilisant Ansible pour automatiser le d√©ploiement et le red√©ploiement d'un code source depuis un d√©p√¥t GitHub.

Dans le header html par exemple indiquer la version du programme et la mention en recette si on est sur la machine alpine3

-----

### **Phase 1 : Pr√©paration de l'H√¥te de Recette (Docker)**

| Exercice | Description | Livrable Attendu |
| :--- | :--- | :--- |
| **1.1** | Cr√©er un fichier `Dockerfile` bas√© sur `alpine:3`. Ce fichier doit inclure l'installation des d√©pendances n√©cessaires pour permettre √† Ansible de fonctionner (ex: Python) et l'installation de `git`. | Fichier `Dockerfile` |
| **1.2** | Construire l'image Docker √† partir du `Dockerfile` (nommez-la `recette-alpine`). | Image Docker `recette-alpine` construite localement |
| **1.3** | Lancer un conteneur en arri√®re-plan √† partir de cette image (nommez-le `recette_hote`). | Conteneur `recette_hote` en cours d'ex√©cution |

-----

### **Phase 2 : Cr√©ation du R√¥le Ansible**

| Exercice | Description | Livrable Attendu |
| :--- | :--- | :--- |
| **2.1** | Initialiser la structure d'un nouveau r√¥le Ansible. Nommez ce r√¥le `deploy_recette`. | R√©pertoire `deploy_recette/` avec la structure standard (`tasks`, `handlers`, etc.) |
| **2.2** | R√©diger les t√¢ches (`tasks/main.yml`) du r√¥le `deploy_recette`. Ces t√¢ches doivent : \<ul\>\<li\>Installer un serveur web (ex: Nginx).\</li\>\<li\>S'assurer que le r√©pertoire de destination (`/opt/app_recette`) existe.\</li\>\<li\>Utiliser le module ad√©quat pour cloner le code source depuis un d√©p√¥t GitHub sp√©cifi√©.\</li\>\<li\>Configurer le serveur web pour servir les fichiers depuis ce r√©pertoire.\</li\>\<li\>S'assurer que le serveur web est d√©marr√©.\</li\>\</ul\> | Fichier `deploy_recette/tasks/main.yml` r√©dig√© |
| **2.3** | R√©diger les *handlers* (`handlers/main.yml`) n√©cessaires. Un *handler* doit √™tre d√©fini pour red√©marrer le serveur web lorsque le code est mis √† jour ou que sa configuration change. | Fichier `deploy_recette/handlers/main.yml` r√©dig√© |

-----

### **Phase 3 : Ex√©cution du D√©ploiement**

| Exercice | Description | Livrable Attendu |
| :--- | :--- | :--- |
| **3.1** | Cr√©er un fichier d'inventaire (`inventory.ini`) pointant vers le conteneur Docker (`recette_hote`). Utiliser le type de connexion `docker` pour que Ansible puisse interagir avec le conteneur. | Fichier `inventory.ini` |
| **3.2** | Cr√©er le *playbook* principal (`deploy.yml`) qui ex√©cute le r√¥le `deploy_recette` sur les h√¥tes d√©finis dans l'inventaire. | Fichier `deploy.yml` |
| **3.3** | Ex√©cuter le *playbook* pour le **premier d√©ploiement**. Analyser le r√©sultat (toutes les t√¢ches devraient √™tre marqu√©es comme `CHANGED`). | Sortie console de l'ex√©cution d'Ansible |

-----

### **Phase 4 : Red√©ploiement et Idempotence**

| Exercice | Description | Livrable Attendu |
| :--- | :--- | :--- |
| **4.1** | Simuler une modification : effectuer un changement dans le code source de l'application sur GitHub, puis *commiter* et *pusher* cette modification. | D√©p√¥t GitHub mis √† jour |
| **4.2** | Ex√©cuter le *playbook* une **seconde fois** (red√©ploiement) sans aucune modification du c√¥t√© Ansible. | Sortie console de l'ex√©cution d'Ansible |


-----

